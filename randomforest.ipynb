{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from operations.adjust_dataset import adjust_dataset\n",
    "from operations.lin import LinearRegressionModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on Test Data: 2.220458029929816\n",
      "1.4901201394283\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('docs/data/GlobalWeatherRepository.csv')\n",
    "\n",
    "df = adjust_dataset(df, 'Kabul')\n",
    "window_size = 7\n",
    "output_size = 3\n",
    "# Create lagged features for temperature_celsius\n",
    "for lag in range(1, window_size + 1):  # Create lags up to the window size\n",
    "    df[f'temp_lag_{lag}'] = df['temperature_celsius'].shift(lag)\n",
    "\n",
    "# Function to create sequences for a single feature (temperature_celsius)\n",
    "def create_temp_sequences(data, window_size, output_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - output_size + 1):\n",
    "        X.append(data[i:(i + window_size)])\n",
    "        y.append(data[i + window_size:i + window_size + output_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences using only temperature_celsius\n",
    "temp_data = df['temperature_celsius']\n",
    "X_seq, y_seq = create_temp_sequences(temp_data, window_size, output_size)\n",
    "\n",
    "\n",
    "# Sequential Train-Test Split\n",
    "train_size_seq = int(len(X_seq) * 0.7)\n",
    "X_train_seq, X_test_seq = X_seq[:train_size_seq], X_seq[train_size_seq:]\n",
    "y_train_seq, y_test_seq = y_seq[:train_size_seq], y_seq[train_size_seq:]\n",
    "\n",
    "# Create weights for the training set - higher weights for more recent data\n",
    "# The weights increase linearly from a starting value (e.g., 1) to an end value (e.g., 10)\n",
    "weights = np.linspace(1, 100, num=len(X_train_seq))\n",
    "\n",
    "\n",
    "# Train the model with these weights\n",
    "model = LinearRegression(copy_X = True, fit_intercept = False, n_jobs = None, positive = True)\n",
    "model.fit(X_train_seq, y_train_seq, sample_weight=weights)\n",
    "\n",
    "# Model is now trained on past temperature data to predict future temperatures\n",
    "# Make predictions on the test set\n",
    "y_pred_seq = model.predict(X_test_seq)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_seq = mean_squared_error(y_test_seq, y_pred_seq)\n",
    "\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Mean Squared Error (MSE) on Test Data: {mse_seq}\")\n",
    "rnse = np.sqrt(mse_seq)\n",
    "print(rnse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random tree forest search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1 Ahead Forecast:\n",
      "  Mean Absolute Error: 0.251\n",
      "  Mean Squared Error: 0.381\n",
      "  Example Predictions (Actual, Predicted):\n",
      "    Actual: 0.08, Predicted: 0.10\n",
      "    Actual: 0.04, Predicted: 0.03\n",
      "    Actual: 0.00, Predicted: 0.01\n",
      "    Actual: 0.00, Predicted: 0.00\n",
      "    Actual: 0.00, Predicted: 0.04\n",
      "\n",
      "\n",
      "Day 2 Ahead Forecast:\n",
      "  Mean Absolute Error: 0.213\n",
      "  Mean Squared Error: 0.205\n",
      "  Example Predictions (Actual, Predicted):\n",
      "    Actual: 0.08, Predicted: 0.03\n",
      "    Actual: 0.00, Predicted: 0.23\n",
      "    Actual: 0.08, Predicted: 0.01\n",
      "    Actual: 0.00, Predicted: 0.03\n",
      "    Actual: 0.00, Predicted: 0.09\n",
      "\n",
      "\n",
      "Day 3 Ahead Forecast:\n",
      "  Mean Absolute Error: 0.197\n",
      "  Mean Squared Error: 0.195\n",
      "  Example Predictions (Actual, Predicted):\n",
      "    Actual: 0.00, Predicted: 0.20\n",
      "    Actual: 0.00, Predicted: 0.12\n",
      "    Actual: 0.08, Predicted: 0.01\n",
      "    Actual: 0.03, Predicted: 0.24\n",
      "    Actual: 0.00, Predicted: 0.04\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('docs/data/GlobalWeatherRepository.csv')\n",
    "\n",
    "# Filtering the DataFrame to keep only the specified cities\n",
    "cities_to_keep = ['Tokyo', 'Madrid', 'Stockholm', 'Paris']\n",
    "df_filtered = df[df['location_name'].isin(cities_to_keep)]\n",
    "\n",
    "# Drop the 'country' column from df_filtered\n",
    "df_filtered = df_filtered.drop(columns=['country', 'timezone', 'last_updated', 'condition_text', 'wind_direction', 'last_updated_epoch', 'wind_degree',\n",
    "                                         'air_quality_us-epa-index', 'air_quality_gb-defra-index', 'moon_illumination','sunrise', 'sunset', 'moonset', 'moonrise', 'moon_phase'])\n",
    "# Now apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_filtered, columns=['location_name'])\n",
    "\n",
    "# Define the target variables\n",
    "#targetvar = ['temperature_celsius', 'wind_kph', 'humidity', 'pressure_mb', 'precip_mm', 'cloud']\n",
    "targetvar = ['temperature_celsius', 'wind_kph', 'pressure_mb', 'precip_mm']\n",
    "\n",
    "\n",
    "\n",
    "window_size = 7  # For example, using the past 7 days to predict\n",
    "target_variable = 'precip_mm'\n",
    "\n",
    "# Split the data into features (X) and target variables (y)\n",
    "#X = df_encoded.drop(columns=target_variable)\n",
    "#y = df_encoded[targetvar]\n",
    "\n",
    "# Create sliding window features\n",
    "for i in range(window_size):\n",
    "    df_encoded[f'{target_variable}_lag_{i+1}'] = df_encoded[target_variable].shift(i+1)\n",
    "\n",
    "# Drop rows with NaN values caused by shifting\n",
    "df_encoded = df_encoded.dropna()\n",
    "# Initialize dictionaries to store models and predictions\n",
    "models = {}\n",
    "predictions = {}\n",
    "mae_scores = {}\n",
    "mse_scores = {}\n",
    "example_predictions = {}\n",
    "\n",
    "# Train a model and predict for each day ahead\n",
    "for day_ahead in range(1, 4):\n",
    "    # Define X and y for this day ahead\n",
    "    X = df_encoded[[f'{target_variable}_lag_{i+1}' for i in range(window_size)]]\n",
    "    y = df_encoded[target_variable].shift(-day_ahead)\n",
    "\n",
    "    # Adjust X and y to have the same length\n",
    "    X = X.iloc[:-day_ahead]\n",
    "    y = y.iloc[:-day_ahead]\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Store the model and make predictions\n",
    "    models[day_ahead] = rf\n",
    "    pred = rf.predict(X_test)\n",
    "    predictions[day_ahead] = rf.predict(X_test)\n",
    "\n",
    "     # Calculate and store metrics\n",
    "    mae_scores[day_ahead] = mean_absolute_error(y_test, pred)\n",
    "    mse_scores[day_ahead] = mean_squared_error(y_test, pred)\n",
    "\n",
    "    # Store example predictions\n",
    "    example_predictions[day_ahead] = list(zip(y_test.head(5), pred[:5]))\n",
    "\n",
    "# Print the results in an easy-to-understand format\n",
    "for day_ahead in range(1, 4):\n",
    "    print(f\"Day {day_ahead} Ahead Forecast:\")\n",
    "    print(f\"  Mean Absolute Error: {mae_scores[day_ahead]:.3f}\")\n",
    "    print(f\"  Mean Squared Error: {mse_scores[day_ahead]:.3f}\")\n",
    "    print(\"  Example Predictions (Actual, Predicted):\")\n",
    "    for actual, predicted in example_predictions[day_ahead]:\n",
    "        print(f\"    Actual: {actual:.2f}, Predicted: {predicted:.2f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ellipsis' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\OMEN\\Documents\\Iot_JM\\linearregression.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mbuild_model()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, num\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X_train_seq))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain_model(sample_weight\u001b[39m=\u001b[39;49mweights)  \u001b[39m# weights as defined in your notebook\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m mse, rmse \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMean Squared Error (MSE) on Test Data: \u001b[39m\u001b[39m{\u001b[39;00mmse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\OMEN\\Documents\\Iot_JM\\operations\\lin.py:20\u001b[0m, in \u001b[0;36mLinearRegressionModel.train_model\u001b[1;34m(self, sample_weight)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(\u001b[39mself\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 20\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_sequences(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train)\n\u001b[0;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(X_train, y_train, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\OMEN\\Documents\\Iot_JM\\operations\\lin.py:35\u001b[0m, in \u001b[0;36mLinearRegressionModel.create_sequences\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_sequences\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m     34\u001b[0m     X, y \u001b[39m=\u001b[39m [], []\n\u001b[1;32m---> 35\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(data) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_size \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     36\u001b[0m         X\u001b[39m.\u001b[39mappend(data[i:(i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size)])\n\u001b[0;32m     37\u001b[0m         y\u001b[39m.\u001b[39mappend(data[i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size:i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_size])\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'ellipsis' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage example\n",
    "y_train_seq = ...  # your y_train data\n",
    "y_test_seq = ...   # your y_test data\n",
    "target_variable = 'temperature_celsius'  # your target variable\n",
    "\n",
    "model = LinearRegressionModel(y_train_seq, y_test_seq, 7, 3, target_variable)\n",
    "model.build_model()\n",
    "weights = np.linspace(1, 100, num=len(X_train_seq))\n",
    "model.train_model(sample_weight=weights)  # weights as defined in your notebook\n",
    "mse, rmse = model.evaluate()\n",
    "print(f\"Mean Squared Error (MSE) on Test Data: {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = model.evaluate()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adjust_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\OMEN\\Documents\\Iot_JM\\linearregression.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdocs/data/GlobalWeatherRepository.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m adjust_dataset(df, \u001b[39m'\u001b[39m\u001b[39mMadrid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m window_size \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/OMEN/Documents/Iot_JM/linearregression.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m output_size \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'adjust_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('docs/data/GlobalWeatherRepository.csv')\n",
    "\n",
    "# Filtering the DataFrame to keep only the specified cities\n",
    "cities_to_keep = ['Tokyo', 'Madrid', 'Stockholm', 'Paris']\n",
    "df_filtered = df[df['location_name'].isin(cities_to_keep)]\n",
    "\n",
    "# Drop the 'country' column from df_filtered\n",
    "df_filtered = df_filtered.drop(columns=['country', 'timezone', 'last_updated', 'condition_text', 'wind_direction', 'last_updated_epoch', 'wind_degree',\n",
    "                                         'air_quality_us-epa-index', 'air_quality_gb-defra-index', 'moon_illumination','sunrise', 'sunset', 'moonset', 'moonrise', 'moon_phase'])\n",
    "# Now apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_filtered, columns=['location_name'])\n",
    "\n",
    "# Define the target variables\n",
    "#targetvar = ['temperature_celsius', 'wind_kph', 'humidity', 'pressure_mb', 'precip_mm', 'cloud']\n",
    "targetvar = ['temperature_celsius', 'wind_kph', 'pressure_mb', 'precip_mm']\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variables (y)\n",
    "X = df_encoded.drop(columns=targetvar)\n",
    "y = df_encoded[targetvar]\n",
    "\n",
    "models = {}\n",
    "mse_scores = {}\n",
    "mae_scores = {}\n",
    "\n",
    "# Train a model for each target variable\n",
    "for var in targetvar:\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, df_encoded[var], test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create and train the model\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Store the model\n",
    "    models[var] = rf\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    mse_scores[var] = mean_squared_error(y_test, predictions)\n",
    "    mae_scores[var] = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "# Print the results\n",
    "for var in targetvar:\n",
    "    print(f\"{var} - Mean Squared Error: {mse_scores[var]}\")\n",
    "    print(f\"{var} - Mean Absolute Error: {mae_scores[var]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'copy_X': True, 'fit_intercept': False, 'n_jobs': None, 'positive': True}\n",
      "Mean Squared Error on Test Set: 8.082073973796033\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'n_jobs': [None, -1],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "#Create the grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "#Fit the grid search to the data\n",
    "grid_search.fit(X_train_seq, y_train_seq)\n",
    "\n",
    "#Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "#Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test_seq)\n",
    "mse = mean_squared_error(y_test_seq, y_pred)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
